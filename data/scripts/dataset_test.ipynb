{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efe90413",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 8 examples [00:00, 1224.75 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'prompt', 'response', 'reward'],\n",
      "    num_rows: 8\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "dataset = load_dataset(\"json\", data_files=\"../train.json\",split=\"train\")\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33ca3727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'prompt', 'response', 'reward'],\n",
      "        num_rows: 8\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset_dict = DatasetDict({\n",
    "    \"train\": dataset\n",
    "})\n",
    "print(dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce71d6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "if os.path.exists(\"../aixue_test_data\"):\n",
    "    shutil.rmtree(\"../aixue_test_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b58a1d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 8/8 [00:00<00:00, 1857.32 examples/s]\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"../aixue_test_data\", exist_ok=True)\n",
    "dataset_dict.save_to_disk(\n",
    "    dataset_dict_path=\"../aixue_test_data\",\n",
    "    max_shard_size=\"500MB\",  # 可选：分片大小控制\n",
    "    num_proc=1,               # 可选：并行进程数\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9f410e",
   "metadata": {},
   "source": [
    "# Response Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01c58e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 17/17 [00:48<00:00,  2.86s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "model_name = \"/root/group-shared/models/base_models/Qwen3-32B\"\n",
    "\n",
    "# load the tokenizer and the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83d29acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thinking content: \n",
      "content: 下一步跟读的句子：**apple**\n",
      "thinking content: \n",
      "content: 下一步跟读的句子：**apple**\n",
      "thinking content: \n",
      "content: 下一步跟读的句子：  \n",
      "**apple**\n",
      "thinking content: \n",
      "content: 下一步跟读的句子：  \n",
      "**apple**\n",
      "thinking content: \n",
      "content: 下一步跟读的句子：  \n",
      "**\"apple\"**  \n",
      "\n",
      "（根据学生学习记录，她在单词“apple”中的辅音/p/发音有瑕疵，因此本次练习聚焦单词发音的精准性，采用纠错策略中的“错误类型B”，直接强化目标单词的正确发音。）\n",
      "thinking content: \n",
      "content: 下一步跟读的句子：**apple** (仅单词，聚焦单词发音练习，纠正辅音 /p/)\n",
      "thinking content: \n",
      "content: 下一步跟读的句子：  \n",
      "**\"apple\"** (仅单词，聚焦单词发音练习，纠正辅音 /p/ 的发音瑕疵)\n",
      "thinking content: \n",
      "content: 下一步跟读的句子：**apple**\n"
     ]
    }
   ],
   "source": [
    "# prepare the model input\n",
    "prompt = \"\"\"你是一名专注于1对1自然拼读教学的英语老师。\n",
    "\n",
    "# 教学目标\n",
    "## 核心课程目标：\n",
    "    1. 建立“字母/字母组合”与“发音”的牢固对应关系（音形联结），掌握单个字母基础发音及常见字母组合发音。\n",
    "    2. 发展学生语音意识（音素、音节、重音感知），提升单词记忆与拼写能力。\n",
    "    3. 最终目标：实现“见词能读，听音能写”。\n",
    "## 单节课教学目标：\n",
    "    1. 个性化教学：根据学生能力调整内容呈现和练习方式，激发兴趣，提升效果。\n",
    "    2. 保持专注与信心：控制单次学习时长，避免连续错误过多，减少疲劳感和挫败感。\n",
    "\n",
    "# 学生画像\n",
    "    1. 年龄：7岁\n",
    "    2. 性别：女\n",
    "    3. 所在地：中国三线城市\n",
    "    4. 英语基础：\n",
    "       - 掌握26个英文字母名称。\n",
    "       - 仅会极少量简单会话（如：What's your name?）。\n",
    "\n",
    "# 当前教学状态\n",
    "    1. 课节内容：教授字母 A、B、C 的发音（a: /æ/, b: /b/, c: /k/）。\n",
    "    2. 当前**环节**：字母 A (/æ/) 的发音练习。\n",
    "    3. 主题关联：教学围绕'苹果 (apple)'展开，练习部分如有单词，建议与之相关。\n",
    "\n",
    "# 教学工具箱 (可选学习范式)\n",
    "## 字母教学包含4种基础练习类型（难度递增）, 例如对于字母a：\n",
    "1. 纯音素重复：`/æ/ /æ/ /æ/` (重复发音3次)\n",
    "2. 音形对应：`a says /æ/` (建立字母与发音关联)\n",
    "3. 音素-单词关联：`/æ/ /æ/ apple` (强化发音在单词中的感知)\n",
    "4. 综合练习：`a says /æ/, /æ/ /æ/ apple` (整合字母、发音与单词)\n",
    "## 智能纠错策略 (根据错误类型选择下一步)\n",
    "1. 错误类型A (字母名称错，发音对)：例如学生说'a says /æ/' (a读错，/æ/正确)。  \n",
    "    **下一步：** 聚焦字母名称练习。老师示范：'a' (仅字母名称)。\n",
    "2. 错误类型B (单词发音错，字母发音对)：例如学生说'/æ/ /æ/ apple' (apple发音错，/æ/正确)。  \n",
    "    **下一步：** 聚焦目标单词练习。老师示范：'apple' (仅单词)。\n",
    "## 教学控制参数\n",
    "1. 单字母(单环节)最大教学次数：4次 (若学生能力强，`综合练习`一次性通过，可减少次数, 直接进入下一个**环节**)。\n",
    "2. 单次跟读最大重复次数：1-2次 (避免疲劳)。\n",
    "3. 核心原则：及时强化正确，精准纠正错误，保持学习动力。\n",
    "\n",
    "# 学生学习记录\n",
    "1. 学习次数：1 次\n",
    "2. 上次练习内容：'/æ/ /æ/ apple'\n",
    "3. 上次表现评分：B (部分正确)\n",
    "4. 具体错误：单词'apple'中的辅音'/p/'发音有瑕疵。\n",
    "\n",
    "# 你的任务：制定下一步教学指令\n",
    "1. **评估：** 基于教学目标、学生基础、当前环节、可选范式、纠错策略、历史表现及教学控制参数，决定下一步的教学。\n",
    "2. 输出格式要求：\n",
    "   - 如果结束当前字母教学，直接回复 <END>\n",
    "   - 如果需要继续学习，直接回复 下一步跟读的句子\"\"\"\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    "    enable_thinking=False # Switches between thinking and non-thinking modes. Default is True.\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# conduct text completion\n",
    "for _ in range(8):\n",
    "    generated_ids = model.generate(\n",
    "        **model_inputs,\n",
    "        max_new_tokens=32768,\n",
    "    )\n",
    "    output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() \n",
    "    \n",
    "    # parsing thinking content\n",
    "    try:\n",
    "        # rindex finding 151668 (</think>)\n",
    "        index = len(output_ids) - output_ids[::-1].index(151668)\n",
    "    except ValueError:\n",
    "        index = 0\n",
    "    \n",
    "    thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
    "    content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "    \n",
    "    print(\"thinking content:\", thinking_content)\n",
    "    print(\"content:\", content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd2689a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the model input\n",
    "prompt = \"\"\"你是一名专注于1对1自然拼读教学的英语老师。\n",
    "\n",
    "# 教学目标\n",
    "## 核心课程目标：\n",
    "    1. 建立“字母/字母组合”与“发音”的牢固对应关系（音形联结），掌握单个字母基础发音及常见字母组合发音。\n",
    "    2. 发展学生语音意识（音素、音节、重音感知），提升单词记忆与拼写能力。\n",
    "    3. 最终目标：实现“见词能读，听音能写”。\n",
    "## 单节课教学目标：\n",
    "    1. 个性化教学：根据学生能力调整内容呈现和练习方式，激发兴趣，提升效果。\n",
    "    2. 保持专注与信心：控制单次学习时长，避免连续错误过多，减少疲劳感和挫败感。\n",
    "\n",
    "# 学生画像\n",
    "    1. 年龄：7岁\n",
    "    2. 性别：女\n",
    "    3. 所在地：中国三线城市\n",
    "    4. 英语基础：\n",
    "       - 掌握26个英文字母名称。\n",
    "       - 仅会极少量简单会话（如：What's your name?）。\n",
    "\n",
    "# 当前教学状态\n",
    "    1. 课节内容：教授字母 A、B、C 的发音（a: /æ/, b: /b/, c: /k/）。\n",
    "    2. 当前**环节**：字母 A (/æ/) 的发音练习。\n",
    "    3. 主题关联：教学围绕'苹果 (apple)'展开，练习部分如有单词，建议与之相关。\n",
    "\n",
    "# 教学工具箱 (可选学习范式)\n",
    "## 字母教学包含4种基础练习类型（难度递增）, 例如对于字母a：\n",
    "1. 纯音素重复：`/æ/ /æ/ /æ/` (重复发音3次)\n",
    "2. 音形对应：`a says /æ/` (建立字母与发音关联)\n",
    "3. 音素-单词关联：`/æ/ /æ/ apple` (强化发音在单词中的感知)\n",
    "4. 综合练习：`a says /æ/, /æ/ /æ/ apple` (整合字母、发音与单词)\n",
    "## 智能纠错策略 (根据错误类型选择下一步)\n",
    "1. 错误类型A (字母名称错，发音对)：例如学生说'a says /æ/' (a读错，/æ/正确)。  \n",
    "    **下一步：** 聚焦字母名称练习。老师示范：'a' (仅字母名称)。\n",
    "2. 错误类型B (单词发音错，字母发音对)：例如学生说'/æ/ /æ/ apple' (apple发音错，/æ/正确)。  \n",
    "    **下一步：** 聚焦目标单词练习。老师示范：'apple' (仅单词)。\n",
    "## 教学控制参数\n",
    "1. 单字母(单环节)最大教学次数：4次 (若学生能力强，`综合练习`一次性通过，可减少次数, 直接进入下一个**环节**)。\n",
    "2. 单次跟读最大重复次数：1-2次 (避免疲劳)。\n",
    "3. 核心原则：及时强化正确，精准纠正错误，保持学习动力。\n",
    "\n",
    "# 学生学习记录\n",
    "1. 学习次数：1 次\n",
    "2. 上次练习内容：'/æ/ /æ/ apple'\n",
    "3. 上次表现评分：B (部分正确)\n",
    "4. 具体错误：单词'apple'中的辅音'/p/'发音有瑕疵。\n",
    "\n",
    "# 你的任务：制定下一步教学指令\n",
    "1. **评估：** 基于教学目标、学生基础、当前环节、可选范式、纠错策略、历史表现及教学控制参数，决定下一步的教学。\n",
    "2. 输出格式要求：\n",
    "   - 如果结束当前字母教学，直接回复 <END>\n",
    "   - 如果需要继续学习，直接回复 下一步跟读的句子\"\"\"\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8209baeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 17/17 [00:40<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thinking content: \n",
      "content: 下一步跟读的句子：**a says /æ/**\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers.modeling_utils import load_sharded_checkpoint\n",
    "\n",
    "model_name = \"/root/group-shared/models/base_models/Qwen3-32B\"\n",
    "\n",
    "# load the tokenizer and the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model_my= AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "checkpoint_path = \"/root/group-shared/jrc/ppo-test/models/4gpu_aixue_data_test/checkpoint-1-out\"\n",
    "\n",
    "\"\"\"\n",
    "# load the tokenizer and the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint_path)\n",
    "\n",
    "model_my = AutoModelForCausalLM.from_pretrained(\n",
    "    checkpoint_path\n",
    ")\n",
    "\"\"\"\n",
    "load_sharded_checkpoint(\n",
    "    model_my,\n",
    "    checkpoint_path\n",
    ")\n",
    "\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    "    enable_thinking=False # Switches between thinking and non-thinking modes. Default is True.\n",
    ")\n",
    "model_my_inputs = tokenizer([text], return_tensors=\"pt\").to(model_my.device)\n",
    "\n",
    "for _ in range(8):\n",
    "    # conduct text completion\n",
    "    generated_ids = model_my.generate(\n",
    "        **model_my_inputs,\n",
    "        max_new_tokens=32768\n",
    "    )\n",
    "    output_ids = generated_ids[0][len(model_my_inputs.input_ids[0]):].tolist() \n",
    "    \n",
    "    # parsing thinking content\n",
    "    try:\n",
    "        # rindex finding 151668 (</think>)\n",
    "        index = len(output_ids) - output_ids[::-1].index(151668)\n",
    "    except ValueError:\n",
    "        index = 0\n",
    "    \n",
    "    thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
    "    content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "    \n",
    "    print(\"thinking content:\", thinking_content)\n",
    "    print(\"content:\", content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1269cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thinking content: \n",
      "content: a says /æ/, /æ/ /æ/ apple\n",
      "thinking content: \n",
      "content: a says /æ/, /æ/ /æ/ apple\n",
      "thinking content: \n",
      "content: a says /æ/, /æ/ /æ/ apple\n",
      "thinking content: \n",
      "content: a says /æ/, /æ/ /æ/ apple\n",
      "thinking content: \n",
      "content: 下一步跟读的句子：**a says /æ/, /æ/ /æ/ apple**\n",
      "thinking content: \n",
      "content: 下一步跟读的句子：`a says /æ/, /æ/ /æ/ apple`\n",
      "thinking content: \n",
      "content: 下一步跟读的句子：  \n",
      "**a says /æ/, /æ/ /æ/ apple**\n",
      "thinking content: \n",
      "content: 下一步跟读的句子：`a says /æ/, /æ/ /æ/ apple`\n"
     ]
    }
   ],
   "source": [
    "for _ in range(8):\n",
    "    # conduct text completion\n",
    "    generated_ids = model_my.generate(\n",
    "        **model_my_inputs,\n",
    "        max_new_tokens=32768\n",
    "    )\n",
    "    output_ids = generated_ids[0][len(model_my_inputs.input_ids[0]):].tolist() \n",
    "    \n",
    "    # parsing thinking content\n",
    "    try:\n",
    "        # rindex finding 151668 (</think>)\n",
    "        index = len(output_ids) - output_ids[::-1].index(151668)\n",
    "    except ValueError:\n",
    "        index = 0\n",
    "    \n",
    "    thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
    "    content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "    \n",
    "    print(\"thinking content:\", thinking_content)\n",
    "    print(\"content:\", content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1904d420",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Error no file named pytorch_model.bin, model.safetensors, tf_model.h5, model.ckpt.index or flax_model.msgpack found in directory /root/group-shared/jrc/ppo-test/models/4gpu_aixue_data_test/checkpoint-1-out.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# load the tokenizer and the model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(checkpoint_path)\n\u001b[0;32m----> 4\u001b[0m model_my \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ppo-test/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:600\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mconfig_class \u001b[38;5;241m==\u001b[39m config\u001b[38;5;241m.\u001b[39msub_configs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    599\u001b[0m         config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget_text_config()\n\u001b[0;32m--> 600\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    604\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    605\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    606\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/ppo-test/lib/python3.10/site-packages/transformers/modeling_utils.py:311\u001b[0m, in \u001b[0;36mrestore_default_torch_dtype.<locals>._wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m old_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mget_default_dtype()\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    313\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_default_dtype(old_dtype)\n",
      "File \u001b[0;32m~/anaconda3/envs/ppo-test/lib/python3.10/site-packages/transformers/modeling_utils.py:4680\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4670\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   4671\u001b[0m     gguf_file\n\u001b[1;32m   4672\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   4673\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m ((\u001b[38;5;28misinstance\u001b[39m(device_map, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisk\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisk\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map)\n\u001b[1;32m   4674\u001b[0m ):\n\u001b[1;32m   4675\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   4676\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOne or more modules is configured to be mapped to disk. Disk offload is not supported for models \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4677\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloaded from GGUF files.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4678\u001b[0m     )\n\u001b[0;32m-> 4680\u001b[0m checkpoint_files, sharded_metadata \u001b[38;5;241m=\u001b[39m \u001b[43m_get_resolved_checkpoint_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4682\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvariant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgguf_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgguf_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_tf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_flax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4687\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_safetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4689\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4690\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4691\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4692\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4693\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4694\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4695\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4696\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_auto_class\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   4697\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransformers_explicit_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformers_explicit_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4698\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4700\u001b[0m is_sharded \u001b[38;5;241m=\u001b[39m sharded_metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   4701\u001b[0m is_quantized \u001b[38;5;241m=\u001b[39m hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ppo-test/lib/python3.10/site-packages/transformers/modeling_utils.py:1089\u001b[0m, in \u001b[0;36m_get_resolved_checkpoint_files\u001b[0;34m(pretrained_model_name_or_path, subfolder, variant, gguf_file, from_tf, from_flax, use_safetensors, cache_dir, force_download, proxies, local_files_only, token, user_agent, revision, commit_hash, is_remote_code, transformers_explicit_filename)\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m   1085\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError no file named \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_add_variant(SAFE_WEIGHTS_NAME,\u001b[38;5;250m \u001b[39mvariant)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m found in directory\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1086\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1087\u001b[0m         )\n\u001b[1;32m   1088\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1089\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m   1090\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError no file named \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_add_variant(WEIGHTS_NAME,\u001b[38;5;250m \u001b[39mvariant)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_add_variant(SAFE_WEIGHTS_NAME,\u001b[38;5;250m \u001b[39mvariant)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1091\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTF2_WEIGHTS_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTF_WEIGHTS_NAME\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.index\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFLAX_WEIGHTS_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m found in directory\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1092\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1093\u001b[0m         )\n\u001b[1;32m   1094\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(subfolder, pretrained_model_name_or_path)):\n\u001b[1;32m   1095\u001b[0m     archive_file \u001b[38;5;241m=\u001b[39m pretrained_model_name_or_path\n",
      "\u001b[0;31mOSError\u001b[0m: Error no file named pytorch_model.bin, model.safetensors, tf_model.h5, model.ckpt.index or flax_model.msgpack found in directory /root/group-shared/jrc/ppo-test/models/4gpu_aixue_data_test/checkpoint-1-out."
     ]
    }
   ],
   "source": [
    "# load the tokenizer and the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint_path)\n",
    "\n",
    "model_my = AutoModelForCausalLM.from_pretrained(\n",
    "    checkpoint_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662fc84e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ppo-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
