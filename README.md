# AIXueRLHF

A variant of PPO to learn from $\langle s, a, r \rangle$ tuples.

## Description

This project implements a variant of Proximal Policy Optimization (PPO) algorithm for reinforcement learning from human feedback (RLHF).

## Features

- PPO variant implementation
- Learning from state-action-reward tuples
- Human feedback integration

## Installation

```bash
pip install -r requirements.txt
```

## Usage

```python
# Example usage will be added here
```

## License

[Add your license here]
